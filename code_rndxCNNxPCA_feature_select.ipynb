{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data handling\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "# data analysis\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import my_ML_algo as algo\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "change_type_map = {'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,\n",
    "                   'Mega Projects': 5}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- read .csv files ---\n"
     ]
    }
   ],
   "source": [
    "# Read csvs\n",
    "print(\"--- read .csv files ---\")\n",
    "train_df = gpd.read_file('train.geojson', index_col=0)\n",
    "# train_df = train_df.dropna()\n",
    "test_df = gpd.read_file('test.geojson', index_col=0)\n",
    "# test_df = test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296146, 45) (120526, 44)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature engineering ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtros\\AppData\\Local\\Temp\\ipykernel_16572\\2939603283.py:9: UserWarning: Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  perimeter = np.asarray(df['geometry'].length)\n",
      "C:\\Users\\jtros\\AppData\\Local\\Temp\\ipykernel_16572\\2939603283.py:14: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  area_values = np.asarray(df['geometry'].area)\n",
      "C:\\Users\\jtros\\AppData\\Local\\Temp\\ipykernel_16572\\2939603283.py:9: UserWarning: Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  perimeter = np.asarray(df['geometry'].length)\n",
      "C:\\Users\\jtros\\AppData\\Local\\Temp\\ipykernel_16572\\2939603283.py:14: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  area_values = np.asarray(df['geometry'].area)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape, train_y.shape, test_x.shape :\n",
      " (296146, 24) (296146,) (120526, 24)\n"
     ]
    }
   ],
   "source": [
    "######## Feature engineering ########\n",
    "print(\"--- Feature engineering ---\")\n",
    "\n",
    "\n",
    "def get_features(df, dataset_type):\n",
    "    dic_features = {\"names\":[],\"features\":[]}\n",
    "\n",
    "    # geometry features\n",
    "    perimeter = np.asarray(df['geometry'].length)\n",
    "    perimeter = np.expand_dims(perimeter, axis=-1)\n",
    "    dic_features[\"features\"].append(perimeter)\n",
    "    dic_features[\"names\"].append(\"perimeter\")\n",
    "\n",
    "    area_values = np.asarray(df['geometry'].area)\n",
    "    area_values = np.expand_dims(area_values, axis=-1)\n",
    "    dic_features[\"features\"].append(area_values)\n",
    "    dic_features[\"names\"].append(\"area_values\")\n",
    "\n",
    "    def get_min_length_ratio(exte):\n",
    "        x, y = exte.xy\n",
    "        lengths = [\n",
    "            np.sqrt((x[i] - x[i + 1]) ** 2 + (y[i] - y[i + 1]) ** 2) for i in range(4)\n",
    "        ]\n",
    "        return np.min(lengths)\n",
    "\n",
    "    def get_max_length_ratio(exte):\n",
    "        x, y = exte.xy\n",
    "        lengths = [\n",
    "            np.sqrt((x[i] - x[i + 1]) ** 2 + (y[i] - y[i + 1]) ** 2) for i in range(4)\n",
    "        ]\n",
    "        return np.max(lengths)\n",
    "\n",
    "    \n",
    "    min_lengths = np.asarray(df[\"geometry\"].exterior.apply(get_min_length_ratio))\n",
    "    min_lengths = np.expand_dims(min_lengths,axis=-1)\n",
    "\n",
    "    max_lengths = np.asarray(df[\"geometry\"].exterior.apply(get_max_length_ratio))\n",
    "    max_lengths = np.expand_dims(max_lengths,axis=-1)\n",
    "\n",
    "    ratio_min_max_lengths = min_lengths/max_lengths\n",
    "    dic_features[\"features\"].append(ratio_min_max_lengths)\n",
    "    dic_features[\"names\"].append(\"ratio_min_max_lengths\")\n",
    "\n",
    "    # dic_features[\"features\"].append(min_lengths)\n",
    "    # dic_features[\"names\"].append(\"min_lengths\")\n",
    "\n",
    "    # dic_features[\"features\"].append(max_lengths)\n",
    "    # dic_features[\"names\"].append(\"max_lengths\")\n",
    "\n",
    "    # diameter\n",
    "    def get_coords(geom):\n",
    "        coords = list(geom.exterior.coords)\n",
    "        return (coords)\n",
    "\n",
    "    def get_diameters(coord):\n",
    "        arr_coord = np.array(coord)\n",
    "        distances = utils.get_distances(arr_coord,arr_coord)\n",
    "        return np.max(distances)\n",
    "\n",
    "    # coords = df.geometry.apply(get_coords)\n",
    "    # diameters = coords.apply(get_diameters)\n",
    "    # diameters = np.asarray(diameters)\n",
    "    # diameters = np.expand_dims(diameters,axis=-1)\n",
    "    # dic_features[\"features\"].append(diameters)\n",
    "    # dic_features[\"names\"].append(\"diameters\")\n",
    "\n",
    "    # ratio_area_over_diameter = perimeter/diameters\n",
    "    # dic_features[\"features\"].append(ratio_area_over_diameter)\n",
    "    # dic_features[\"names\"].append(\"ratio_area_over_diameter\")\n",
    "\n",
    "    # ratio_perimeter_over_diameter = area_values/diameters\n",
    "    # dic_features[\"features\"].append(ratio_perimeter_over_diameter)\n",
    "    # dic_features[\"names\"].append(\"ratio_perimeter_over_diameter\")\n",
    "\n",
    "    # geography features\n",
    "    # mlb_urban_type = MultiLabelBinarizer()\n",
    "    # urban_type = np.asarray(df[\"urban_type\"].apply(lambda x: x.split(\",\") if x!=\"N,A\" else [x]))\n",
    "    # urban_type = [urban_type[row] for row in range(urban_type.shape[0])]\n",
    "    # urban_type = mlb_urban_type.fit_transform(urban_type)\n",
    "    # dic_features[\"features\"].append(urban_type)\n",
    "    # dic_features[\"names\"]+=list(mlb_urban_type.classes_)\n",
    "    \n",
    "    le_urban_type = LabelEncoder()\n",
    "    urban_type = np.asarray(df[\"urban_type\"])\n",
    "    le_urban_type.fit(urban_type)\n",
    "    # print(\"possible urban_type list :\", list(le_urban_type.classes_))\n",
    "    urban_type = le_urban_type.transform(urban_type)\n",
    "    urban_type = np.expand_dims(urban_type, axis=-1)\n",
    "    dic_features[\"features\"].append(urban_type)\n",
    "    dic_features[\"names\"].append(\"urban_type\")\n",
    "\n",
    "    # mlb_geography_type = MultiLabelBinarizer()\n",
    "    # geography_type = np.asarray(df[\"geography_type\"].apply(lambda x: x.split(\",\") if x!=\"N,A\" else [x]))\n",
    "    # geography_type = mlb_geography_type.fit_transform(geography_type)\n",
    "    # dic_features[\"features\"].append(geography_type)\n",
    "    # dic_features[\"names\"]+=list(mlb_geography_type.classes_)\n",
    "\n",
    "    # add sequence features\n",
    "\n",
    "    kept_columns_dense_32 = [0,6,15,19]\n",
    "    model_dense_32_output = np.load(f\"save/outputs/model_dense_32_{dataset_type}_output_5000_train_steps_no_val.npz\")[\"arr_0\"][:,kept_columns_dense_32]\n",
    "    dic_features[\"features\"].append(model_dense_32_output)\n",
    "    dic_features[\"names\"]+=[f\"model_dense_32_output_{j}\" for j in kept_columns_dense_32]\n",
    "\n",
    "    kept_columns_dense_16 = [15,6,1]\n",
    "    model_dense_16_output = np.load(f\"save/outputs/model_dense_16_{dataset_type}_output_5000_train_steps_no_val.npz\")[\"arr_0\"]\n",
    "    model_dense_16_output = model_dense_16_output[:,kept_columns_dense_16]\n",
    "    dic_features[\"features\"].append(model_dense_16_output)\n",
    "    dic_features[\"names\"]+=[f\"model_dense_16_output_{j}\" for j in kept_columns_dense_16]\n",
    "\n",
    "    \n",
    "    # PCA on sequence features :\n",
    "    # PCA_kept_columns_dense_32 = [6, 3, 4, 2, 5][:3]\n",
    "    # model_dense_32_output = np.load(f\"save/old/model_dense_32_{dataset_type}_output_val_0f7151.npz\")[\"arr_0\"]\n",
    "    # PCA_model_dense_32_output = algo.apply_PCA(model_dense_32_output)[:,PCA_kept_columns_dense_32]\n",
    "    # print(\"PCA 32 : \",PCA_model_dense_32_output.shape)\n",
    "    # dic_features[\"features\"].append(PCA_model_dense_32_output)\n",
    "    # dic_features[\"names\"]+=[f\"PCA_model_dense_32_output_{j}\" for j in np.arange(PCA_model_dense_32_output.shape[-1])]\n",
    "\n",
    "    # kept_PCA_columns_dense_16 = np.arange(4)\n",
    "    # model_dense_16_output = np.load(f\"save/old/model_dense_16_{dataset_type}_output_val_0f7151.npz\")[\"arr_0\"]\n",
    "    # PCA_model_dense_16_output = algo.apply_PCA(model_dense_16_output)[:,kept_PCA_columns_dense_16]\n",
    "    # print(\"PCA 16 : \",PCA_model_dense_16_output.shape)\n",
    "    # dic_features[\"features\"].append(PCA_model_dense_16_output)\n",
    "    # dic_features[\"names\"]+=[f\"PCA_model_dense_16_output_{j}\" for j in np.arange(PCA_model_dense_16_output.shape[-1])]\n",
    "\n",
    "\n",
    "    # for feat in features:\n",
    "    #     print(feat.shape)\n",
    "\n",
    "    res = np.concatenate(dic_features[\"features\"], axis=-1)\n",
    "\n",
    "    return res,dic_features\n",
    "\n",
    "\n",
    "train_x,train_dic_features = get_features(train_df,dataset_type=\"train\")\n",
    "train_y = train_df['change_type'].apply(lambda x: change_type_map[x])\n",
    "\n",
    "index_x = test_df[\"index\"]\n",
    "test_x,_ = get_features(test_df,dataset_type=\"test\")\n",
    "\n",
    "print(\"train_x.shape, train_y.shape, test_x.shape :\\n\",\n",
    "      train_x.shape, train_y.shape, test_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****\n",
      "---- best_features so far: [0, 1, 2, 3, 4, 5, 6, 7]  ----\n",
      "---- perf so far: 0  ----\n",
      "---- remaining_features so far: [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]  ----\n",
      "\n",
      "---- ---- ratio features explored: 0.0\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
      "---- ---- perf: 0.33963783239292017\n",
      "---- ---- time execution iteration: 47.23449945449829\n",
      "\n",
      "---- ---- ratio features explored: 0.0625\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 9]\n",
      "---- ---- perf: 0.3775475345531448\n",
      "---- ---- time execution iteration: 57.2589430809021\n",
      "\n",
      "---- ---- ratio features explored: 0.125\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 10]\n",
      "---- ---- perf: 0.3400499843885996\n",
      "---- ---- time execution iteration: 50.68463182449341\n",
      "\n",
      "---- ---- ratio features explored: 0.1875\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 11]\n",
      "---- ---- perf: 0.3438807490223732\n",
      "---- ---- time execution iteration: 50.55091571807861\n",
      "\n",
      "---- ---- ratio features explored: 0.25\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 12]\n",
      "---- ---- perf: 0.3448286381185887\n",
      "---- ---- time execution iteration: 49.40717267990112\n",
      "\n",
      "---- ---- ratio features explored: 0.3125\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 13]\n",
      "---- ---- perf: 0.4481209928372727\n",
      "---- ---- time execution iteration: 55.700092792510986\n",
      "\n",
      "---- ---- ratio features explored: 0.375\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 14]\n",
      "---- ---- perf: 0.46707739061427744\n",
      "---- ---- time execution iteration: 56.66062593460083\n",
      "\n",
      "---- ---- ratio features explored: 0.4375\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 15]\n",
      "---- ---- perf: 0.3608768793695868\n",
      "---- ---- time execution iteration: 52.139747858047485\n",
      "\n",
      "---- ---- ratio features explored: 0.5\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 16]\n",
      "---- ---- perf: 0.34354825153338386\n",
      "---- ---- time execution iteration: 54.71003031730652\n",
      "\n",
      "---- ---- ratio features explored: 0.5625\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 17]\n",
      "---- ---- perf: 0.33976616295181455\n",
      "---- ---- time execution iteration: 50.94885230064392\n",
      "\n",
      "---- ---- ratio features explored: 0.625\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 18]\n",
      "---- ---- perf: 0.4205631493988823\n",
      "---- ---- time execution iteration: 55.000652551651\n",
      "\n",
      "---- ---- ratio features explored: 0.6875\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 19]\n",
      "---- ---- perf: 0.3685902740365807\n",
      "---- ---- time execution iteration: 47.70344305038452\n",
      "\n",
      "---- ---- ratio features explored: 0.75\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 20]\n",
      "---- ---- perf: 0.34085962388298735\n",
      "---- ---- time execution iteration: 46.44225096702576\n",
      "\n",
      "---- ---- ratio features explored: 0.8125\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 21]\n",
      "---- ---- perf: 0.3454420008832882\n",
      "---- ---- time execution iteration: 46.80524134635925\n",
      "\n",
      "---- ---- ratio features explored: 0.875\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 22]\n",
      "---- ---- perf: 0.3769647007131004\n",
      "---- ---- time execution iteration: 52.65410757064819\n",
      "\n",
      "---- ---- ratio features explored: 0.9375\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23]\n",
      "---- ---- perf: 0.4748000105422506\n",
      "---- ---- time execution iteration: 55.52609658241272\n",
      "\n",
      "---- can_explore: True  ----\n",
      "*****\n",
      "*****\n",
      "---- best_features so far: [0, 1, 2, 3, 4, 5, 6, 7, 23]  ----\n",
      "---- perf so far: 0.4748000105422506  ----\n",
      "---- remaining_features so far: [8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]  ----\n",
      "\n",
      "---- ---- ratio features explored: 0.0\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 8]\n",
      "---- ---- perf: 0.4747725755449311\n",
      "---- ---- time execution iteration: 50.53368353843689\n",
      "\n",
      "---- ---- ratio features explored: 0.06666666666666667\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 9]\n",
      "---- ---- perf: 0.513667465140101\n",
      "---- ---- time execution iteration: 56.18922448158264\n",
      "\n",
      "---- ---- ratio features explored: 0.13333333333333333\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 10]\n",
      "---- ---- perf: 0.47538512132310695\n",
      "---- ---- time execution iteration: 49.84531617164612\n",
      "\n",
      "---- ---- ratio features explored: 0.2\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 11]\n",
      "---- ---- perf: 0.4748568769044688\n",
      "---- ---- time execution iteration: 49.24420189857483\n",
      "\n",
      "---- ---- ratio features explored: 0.26666666666666666\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 12]\n",
      "---- ---- perf: 0.4755120378122477\n",
      "---- ---- time execution iteration: 49.88056755065918\n",
      "\n",
      "---- ---- ratio features explored: 0.3333333333333333\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 13]\n",
      "---- ---- perf: 0.4920568397438113\n",
      "---- ---- time execution iteration: 55.62693738937378\n",
      "\n",
      "---- ---- ratio features explored: 0.4\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 14]\n",
      "---- ---- perf: 0.5165421325146998\n",
      "---- ---- time execution iteration: 56.87273597717285\n",
      "\n",
      "---- ---- ratio features explored: 0.4666666666666667\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 15]\n",
      "---- ---- perf: 0.47751242537487026\n",
      "---- ---- time execution iteration: 52.8543426990509\n",
      "\n",
      "---- ---- ratio features explored: 0.5333333333333333\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 16]\n",
      "---- ---- perf: 0.4744331671573017\n",
      "---- ---- time execution iteration: 51.77513074874878\n",
      "\n",
      "---- ---- ratio features explored: 0.6\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 17]\n",
      "---- ---- perf: 0.47481886276657437\n",
      "---- ---- time execution iteration: 51.08379864692688\n",
      "\n",
      "---- ---- ratio features explored: 0.6666666666666666\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 18]\n",
      "---- ---- perf: 0.4818918953004103\n",
      "---- ---- time execution iteration: 61.44036817550659\n",
      "\n",
      "---- ---- ratio features explored: 0.7333333333333333\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 19]\n",
      "---- ---- perf: 0.4760558783312024\n",
      "---- ---- time execution iteration: 56.12194466590881\n",
      "\n",
      "---- ---- ratio features explored: 0.8\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 20]\n",
      "---- ---- perf: 0.475551182381977\n",
      "---- ---- time execution iteration: 53.75698637962341\n",
      "\n",
      "---- ---- ratio features explored: 0.8666666666666667\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 21]\n",
      "---- ---- perf: 0.4763192604783707\n",
      "---- ---- time execution iteration: 54.386802434921265\n",
      "\n",
      "---- ---- ratio features explored: 0.9333333333333333\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 22]\n",
      "---- ---- perf: 0.504968266539691\n",
      "---- ---- time execution iteration: 60.17381691932678\n",
      "\n",
      "---- can_explore: True  ----\n",
      "*****\n",
      "*****\n",
      "---- best_features so far: [0, 1, 2, 3, 4, 5, 6, 7, 23, 14]  ----\n",
      "---- perf so far: 0.5165421325146998  ----\n",
      "---- remaining_features so far: [8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22]  ----\n",
      "\n",
      "---- ---- ratio features explored: 0.0\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 14, 8]\n",
      "---- ---- perf: 0.5171816148428195\n",
      "---- ---- time execution iteration: 55.7211275100708\n",
      "\n",
      "---- ---- ratio features explored: 0.07142857142857142\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 14, 9]\n",
      "---- ---- perf: 0.5531259661398091\n",
      "---- ---- time execution iteration: 62.22223663330078\n",
      "\n",
      "---- ---- ratio features explored: 0.14285714285714285\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 14, 10]\n",
      "---- ---- perf: 0.5183048770552827\n",
      "---- ---- time execution iteration: 54.50833749771118\n",
      "\n",
      "---- ---- ratio features explored: 0.21428571428571427\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 14, 11]\n",
      "---- ---- perf: 0.5153042383397963\n",
      "---- ---- time execution iteration: 55.27229309082031\n",
      "\n",
      "---- ---- ratio features explored: 0.2857142857142857\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 14, 12]\n",
      "---- ---- perf: 0.5168262571614121\n",
      "---- ---- time execution iteration: 52.13416385650635\n",
      "\n",
      "---- ---- ratio features explored: 0.35714285714285715\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 14, 13]\n",
      "---- ---- perf: 0.5262063870702435\n",
      "---- ---- time execution iteration: 58.345741987228394\n",
      "\n",
      "---- ---- ratio features explored: 0.42857142857142855\n",
      "---- ---- features_kept: [0, 1, 2, 3, 4, 5, 6, 7, 23, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "best_features_init = list(np.arange(8))\n",
    "print(\"best features to keep:\",algo.forward_selection(train_x,train_y, significance_level=0.01,best_features_init=best_features_init))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_id_to_keep = list(set(np.arange(train_x.shape[-1]))-set([]))\n",
    "extracted_train_x = train_x[:,features_id_to_keep]\n",
    "extracted_test_x = test_x[:,features_id_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- train ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   11.3s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on training set : 0.9999235361075586\n",
      "prediction on test set shape : (296146,)\n",
      "perimeter importance: 0.17927484213846892\n",
      "area_values importance: 0.006445515156503034\n",
      "ratio_min_max_lengths importance: 0.143966692240987\n",
      "urban_type importance: 0.047291272069124195\n",
      "model_dense_32_output_0 importance: 0.1361580941790445\n",
      "model_dense_32_output_6 importance: 0.1843413663405821\n",
      "model_dense_32_output_15 importance: 0.04420786344941158\n",
      "model_dense_32_output_19 importance: 0.037097514885244764\n",
      "model_dense_16_output_1 importance: 0.1780104094960045\n",
      "model_dense_16_output_4 importance: 0.007312474340219226\n",
      "model_dense_16_output_8 importance: 0.034157933233957445\n",
      "model_dense_16_output_9 importance: 0.0017360224704526918\n",
      "[48, 49, 55, 51, 53, 48, 55, 52, 49, 51, 53, 53, 50, 47, 49, 46, 47, 51, 46, 59, 60, 49, 51, 52, 53, 48, 51, 49, 49, 54, 53, 51, 48, 50, 49, 50, 52, 51, 50, 50, 46, 46, 51, 48, 52, 52, 51, 52, 49, 54, 50, 52, 51, 52, 49, 50, 48, 52, 52, 50, 48, 48, 48, 55, 50, 55, 69, 50, 49, 55, 49, 49, 50, 46, 51, 49, 49, 54, 49, 49, 49, 53, 53, 47, 53, 51, 52, 49, 54, 47, 48, 48, 52, 47, 49, 49, 52, 52, 45, 49]\n",
      "[67665, 68343, 68814, 68434, 68471, 68329, 69007, 67981, 68788, 69240, 69464, 68400, 67733, 69216, 67677, 68695, 67730, 67964, 67676, 68627, 68881, 69157, 68217, 69551, 68577, 66816, 68247, 68717, 68663, 66241, 66814, 68623, 67477, 68338, 67892, 68962, 69284, 67800, 66893, 68912, 68668, 67568, 68182, 67252, 64078, 66831, 68132, 67297, 67871, 68922, 68743, 68967, 68630, 67797, 67090, 66896, 66503, 68315, 66608, 68691, 68942, 68851, 67432, 68446, 67538, 67804, 69342, 68459, 67556, 68287, 67080, 68073, 67943, 68157, 66479, 67074, 68387, 68251, 68328, 68264, 69119, 68679, 67814, 67712, 67652, 64131, 67680, 68634, 68492, 69090, 68096, 66733, 68169, 68527, 68584, 67604, 68952, 67449, 68443, 67864]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.6s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.6s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.7s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.6s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.2s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.2s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.9s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   10.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [0.40903499 0.40323326 0.41983164 0.39189278 0.40243189 0.39471981\n",
      " 0.37076696 0.38227393 0.41861951 0.42228183]\n",
      "Mean 0.4015086606573693\n",
      "Std: 0.01604397074603381\n",
      "experiment saved at ./results/automatic_study_features_rndxCNN.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jtros\\CS\\cours\\Cours_de_2A\\electifML\\geoproject\\utils.py:97: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df_read.append(new_df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "######## Training ########\n",
    "print(\"--- train ---\")\n",
    "rnd_clf = RandomForestClassifier(verbose=1,n_jobs=-1)\n",
    "\n",
    "rnd_clf.fit(extracted_train_x,train_y)\n",
    "pred_y = rnd_clf.predict(extracted_train_x)\n",
    "train_rnd_clf_f1_score = f1_score(pred_y, train_y,average='macro')\n",
    "print(\"f1_score on training set :\", train_rnd_clf_f1_score)\n",
    "print(\"prediction on test set shape :\", pred_y.shape)\n",
    "\n",
    "utils.display_feature_importances(train_dic_features,rnd_clf)\n",
    "\n",
    "print([estimator.get_depth() for estimator in rnd_clf.estimators_])\n",
    "print([estimator.get_n_leaves() for estimator in rnd_clf.estimators_])\n",
    "\n",
    "utils.plot_and_save_confusion_matrix(pred_y,train_y,\"./results/confusion_matrix_simple_rnd_clfxCNN.png\")\n",
    "\n",
    "\n",
    "\n",
    "k_fold_number = 10\n",
    "val_scores = [-1]\n",
    "if k_fold_number>1:\n",
    "    def display_scores(scores):\n",
    "        print(\"Scores:\",scores)\n",
    "        print(\"Mean\",scores.mean())\n",
    "        print(\"Std:\",scores.std())\n",
    "    val_scores = cross_val_score(rnd_clf,extracted_train_x,train_y,scoring=\"f1_macro\",cv=k_fold_number)\n",
    "    display_scores(val_scores)\n",
    "\n",
    "    utils.save_experiment_in_excel(\"./results/automatic_study_features_rndxCNN.xlsx\",rnd_clf,train_rnd_clf_f1_score,k_fold_number,val_scores,train_dic_features,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- save ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "######## Save results to submission file ########\n",
    "pred_y = rnd_clf.predict(extracted_test_x)\n",
    "print(\"--- save ---\")\n",
    "pred_df = pd.DataFrame(pred_y, columns=['change_type'])\n",
    "pred_df.to_csv(\"my_submissions/greedy.csv\", index=True, index_label='Id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_geoproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a691981180cc6a4785b1489b0832c35bb891551f8845804eee4cb510316e0ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
