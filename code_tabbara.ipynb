{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- read .csv files ---\n"
     ]
    }
   ],
   "source": [
    "# data handling\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "# data analysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "change_type_map = {'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,\n",
    "                   'Mega Projects': 5}\n",
    "\n",
    "# Read csvs\n",
    "print(\"--- read .csv files ---\")\n",
    "train_df = gpd.read_file('train.geojson', index_col=0)\n",
    "# train_df = train_df.dropna()\n",
    "test_df = gpd.read_file('test.geojson', index_col=0)\n",
    "# test_df = test_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296146, 45) (120526, 44)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_ratio(exte):\n",
    "    x, y = exte.xy\n",
    "    lengths = [\n",
    "        np.sqrt((x[i] - x[i + 1]) ** 2 + (y[i] - y[i + 1]) ** 2) for i in range(4)\n",
    "    ]\n",
    "    return np.min(lengths) / np.max(lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature engineering ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jtros\\AppData\\Local\\Temp\\ipykernel_23916\\1970154489.py:11: UserWarning: Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  perimeter = np.asarray(df['geometry'].length)\n",
      "C:\\Users\\jtros\\AppData\\Local\\Temp\\ipykernel_23916\\1970154489.py:15: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  area_values = np.asarray(df['geometry'].area)\n",
      "C:\\Users\\jtros\\AppData\\Local\\Temp\\ipykernel_23916\\1970154489.py:11: UserWarning: Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  perimeter = np.asarray(df['geometry'].length)\n",
      "C:\\Users\\jtros\\AppData\\Local\\Temp\\ipykernel_23916\\1970154489.py:15: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  area_values = np.asarray(df['geometry'].area)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x.shape, train_y.shape, test_x.shape :\n",
      " (296146, 4) (296146,) (120526, 4)\n"
     ]
    }
   ],
   "source": [
    "######## Feature engineering ########\n",
    "print(\"--- Feature engineering ---\")\n",
    "\n",
    "\n",
    "def get_features(df, begin_index = 3):\n",
    "    # columns = df.columns\n",
    "    # features = [np.expand_dims(np.asarray(df[column]), axis = -1) for column in columns[begin_index : -12]] #TODO modify this line to sort images chronologically\n",
    "\n",
    "    features = []\n",
    "    # geometry features\n",
    "    perimeter = np.asarray(df['geometry'].length)\n",
    "    perimeter = np.expand_dims(perimeter, axis=-1)\n",
    "    features.append(perimeter)\n",
    "\n",
    "    area_values = np.asarray(df['geometry'].area)\n",
    "    area_values = np.expand_dims(area_values, axis=-1)\n",
    "    features.append(area_values)\n",
    "\n",
    "    ratios = np.asarray(df[\"geometry\"].exterior.apply(length_ratio))\n",
    "    ratios = np.expand_dims(ratios, axis=-1)\n",
    "    features.append(ratios)\n",
    "    \n",
    "    # geography features\n",
    "    le_urban_type = LabelEncoder()\n",
    "    urban_type = np.asarray(df[\"urban_type\"])\n",
    "    le_urban_type.fit(urban_type)\n",
    "    # print(\"possible urban_type list :\", list(le_urban_type.classes_))\n",
    "    urban_type = le_urban_type.transform(urban_type)\n",
    "    urban_type = np.expand_dims(urban_type, axis=-1)\n",
    "    features.append(urban_type)\n",
    "\n",
    "    # le_geography_type = LabelEncoder()\n",
    "    # geography_type = np.asarray(df[\"geography_type\"])\n",
    "    # le_geography_type.fit(geography_type)\n",
    "    # # print(\"possible geography_type list :\", list(le_geography_type.classes_))\n",
    "    # geography_type = le_geography_type.transform(geography_type)\n",
    "    # geography_type = np.expand_dims(geography_type, axis=-1)\n",
    "    # features.append(geography_type)\n",
    "\n",
    "    # for feat in features:\n",
    "    #     print(feat.shape)\n",
    "\n",
    "    res = np.concatenate(features, axis=-1)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "train_x = get_features(train_df)\n",
    "train_y = train_df['change_type'].apply(lambda x: change_type_map[x])\n",
    "\n",
    "index_x = test_df[\"index\"]\n",
    "test_x = get_features(test_df, begin_index=2)\n",
    "\n",
    "print(\"train_x.shape, train_y.shape, test_x.shape :\\n\",\n",
    "      train_x.shape, train_y.shape, test_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- train ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    3.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on training set : 0.9536415125584977\n",
      "prediction on test set shape : (296146,)\n",
      "feat_name importance: 0.47392575177934826\n",
      "feat_name importance: 0.011533393361079215\n",
      "feat_name importance: 0.4752358348571511\n",
      "feat_name importance: 0.03930502000242144\n",
      "[63, 90, 60, 58, 63, 66, 64, 63, 69, 63, 63, 64, 67, 60, 65, 60, 71, 72, 64, 63, 63, 63, 65, 63, 64, 62, 65, 70, 68, 61, 68, 70, 84, 76, 67, 59, 66, 64, 68, 60, 62, 68, 75, 65, 65, 66, 66, 63, 62, 67, 70, 67, 69, 72, 76, 63, 71, 60, 65, 64, 59, 62, 77, 62, 71, 65, 70, 62, 72, 76, 69, 65, 63, 69, 60, 66, 61, 57, 67, 63, 70, 58, 73, 62, 59, 66, 63, 64, 60, 71, 66, 73, 63, 75, 63, 66, 67, 69, 61, 61]\n",
      "[61083, 83217, 77565, 79244, 84507, 82887, 81025, 78822, 79523, 80517, 81999, 72085, 81643, 76369, 81352, 79626, 86832, 86156, 79930, 78705, 83485, 73427, 85299, 84924, 74924, 82933, 84723, 85855, 80116, 83725, 74961, 81821, 82194, 83737, 78417, 82487, 84623, 84282, 83112, 85271, 81091, 80919, 32134, 87623, 82584, 83486, 82965, 82152, 82872, 80238, 84218, 78402, 82922, 83063, 81463, 78809, 81485, 82960, 83653, 84753, 83959, 80915, 67311, 78896, 77716, 81484, 85615, 85843, 78411, 85515, 82975, 85138, 80825, 81215, 84862, 79847, 70102, 83704, 83498, 81007, 83777, 84202, 76620, 80659, 79941, 87026, 83415, 79613, 79511, 80417, 82389, 87546, 84845, 83543, 84824, 83196, 85311, 78268, 81363, 73927]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- save ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 100 out of 100 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "######## Training ########\n",
    "print(\"--- train ---\")\n",
    "rnd_clf = RandomForestClassifier(verbose=1,n_jobs=-1)\n",
    "\n",
    "rnd_clf.fit(train_x,train_y)\n",
    "pred_y = rnd_clf.predict(train_x)\n",
    "print(\"f1_score on training set :\", f1_score(pred_y, train_y,average='macro'))\n",
    "print(\"prediction on test set shape :\", pred_y.shape)\n",
    "\n",
    "for i in range(len(rnd_clf.feature_importances_)):\n",
    "    print(\"feat_name importance:\", rnd_clf.feature_importances_[i])\n",
    "\n",
    "print([estimator.get_depth() for estimator in rnd_clf.estimators_])\n",
    "print([estimator.get_n_leaves() for estimator in rnd_clf.estimators_])\n",
    "\n",
    "utils.plot_and_save_confusion_matrix(pred_y,train_y,\"./results/confusion_matrix_simple_rnd_clf.png\")\n",
    "\n",
    "######## Save results to submission file ########\n",
    "pred_y = rnd_clf.predict(test_x)\n",
    "print(\"--- save ---\")\n",
    "pred_df = pd.DataFrame(pred_y, columns=['change_type'])\n",
    "pred_df.to_csv(\"my_submission_paul_root.csv\", index=True, index_label='Id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_geoproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a691981180cc6a4785b1489b0832c35bb891551f8845804eee4cb510316e0ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
