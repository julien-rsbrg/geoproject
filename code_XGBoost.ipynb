{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- read .csv files ---\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script can be used as skeleton code to read the challenge train and test\n",
    "geojsons, to train a trivial model, and write data to the submission file.\n",
    "\"\"\"\n",
    "# data handling\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "# data analysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "change_type_map = {'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,\n",
    "                   'Mega Projects': 5}\n",
    "\n",
    "# Read csvs\n",
    "print(\"--- read .csv files ---\")\n",
    "train_df = gpd.read_file('train.geojson', index_col=0)\n",
    "\n",
    "test_df = gpd.read_file('test.geojson', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of lines at first: 120526\n",
      "number of lines without na: 119176\n",
      "(1350,)\n",
      "(120526,)\n",
      "(120526, 44)\n"
     ]
    }
   ],
   "source": [
    "def handle_na_in_df(df):\n",
    "    print(\"number of lines at first:\",df.shape[0])\n",
    "    df_without_na = df.dropna()\n",
    "    print(\"number of lines without na:\",df_without_na.shape[0])\n",
    "    indices_without_na = np.asarray(df_without_na.index)\n",
    "    df_with_na = df[df.isna().any(axis=1)]\n",
    "    indices_with_na = np.asarray(df_with_na.index)\n",
    "\n",
    "    indices = np.concatenate([indices_without_na,indices_with_na],axis=0)\n",
    "\n",
    "    dummy_values = 2*np.ones((indices_with_na.shape[0],))\n",
    "\n",
    "    return df_without_na,indices,dummy_values\n",
    "\n",
    "df_without_na,indices,dummy_values = handle_na_in_df(test_df)\n",
    "print(dummy_values.shape)\n",
    "print(indices.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['urban_type', 'geography_type', 'change_type', 'img_red_mean_date1',\n",
      "       'img_green_mean_date1', 'img_blue_mean_date1', 'img_red_std_date1',\n",
      "       'img_green_std_date1', 'img_blue_std_date1', 'img_red_mean_date2',\n",
      "       'img_green_mean_date2', 'img_blue_mean_date2', 'img_red_std_date2',\n",
      "       'img_green_std_date2', 'img_blue_std_date2', 'img_red_mean_date3',\n",
      "       'img_green_mean_date3', 'img_blue_mean_date3', 'img_red_std_date3',\n",
      "       'img_green_std_date3', 'img_blue_std_date3', 'img_red_mean_date4',\n",
      "       'img_green_mean_date4', 'img_blue_mean_date4', 'img_red_std_date4',\n",
      "       'img_green_std_date4', 'img_blue_std_date4', 'img_red_mean_date5',\n",
      "       'img_green_mean_date5', 'img_blue_mean_date5', 'img_red_std_date5',\n",
      "       'img_green_std_date5', 'img_blue_std_date5', 'date0',\n",
      "       'change_status_date0', 'date1', 'change_status_date1', 'date2',\n",
      "       'change_status_date2', 'date3', 'change_status_date3', 'date4',\n",
      "       'change_status_date4', 'index', 'geometry'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature engineering ---\n",
      "number of lines at first: 296146\n",
      "number of lines without na: 292758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-6b7305125569>:8: UserWarning: Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  perimeter = np.asarray(df['geometry'].length)\n",
      "<ipython-input-6-6b7305125569>:13: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  area_values = np.asarray(df['geometry'].area)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible urban_type list : ['Dense Urban', 'Industrial', 'N,A', 'Rural', 'Sparse Urban', 'Urban Slum']\n",
      "possible geography_type list : ['Barren Land', 'Coastal', 'Dense Forest', 'Desert', 'Farms', 'Grass Land', 'Hills', 'Lakes', 'N,A', 'River', 'Snow', 'Sparse Forest']\n",
      "geography_type [[0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n",
      "['perimeter'] (292758, 1)\n",
      "['area'] (292758, 1)\n",
      "['ratio_area_over_perimeter'] (292758, 1)\n",
      "['ratio_length_min_max'] (292758, 1)\n",
      "['Dense Urban', 'Industrial', 'N,A', 'Rural', 'Sparse Urban', 'Urban Slum'] (292758, 6)\n",
      "['Barren Land', 'Coastal', 'Dense Forest', 'Desert', 'Farms', 'Grass Land', 'Hills', 'Lakes', 'N,A', 'River', 'Snow', 'Sparse Forest'] (292758, 12)\n",
      "['new_date_diff0', 'new_date_diff1', 'new_date_diff2', 'new_date_diff3', 'new_date_diff4'] (292758, 5)\n",
      "['color_mean_std_0_0_0', 'color_mean_std_1_0_0', 'color_mean_std_2_0_0', 'color_mean_std_3_0_0', 'color_mean_std_4_0_0'] (292758, 5)\n",
      "['color_mean_std_0_0_1', 'color_mean_std_1_0_1', 'color_mean_std_2_0_1', 'color_mean_std_3_0_1', 'color_mean_std_4_0_1'] (292758, 5)\n",
      "['color_mean_std_0_1_0', 'color_mean_std_1_1_0', 'color_mean_std_2_1_0', 'color_mean_std_3_1_0', 'color_mean_std_4_1_0'] (292758, 5)\n",
      "['color_mean_std_0_1_1', 'color_mean_std_1_1_1', 'color_mean_std_2_1_1', 'color_mean_std_3_1_1', 'color_mean_std_4_1_1'] (292758, 5)\n",
      "['color_mean_std_0_2_0', 'color_mean_std_1_2_0', 'color_mean_std_2_2_0', 'color_mean_std_3_2_0', 'color_mean_std_4_2_0'] (292758, 5)\n",
      "['color_mean_std_0_2_1', 'color_mean_std_1_2_1', 'color_mean_std_2_2_1', 'color_mean_std_3_2_1', 'color_mean_std_4_2_1'] (292758, 5)\n",
      "number of lines at first: 120526\n",
      "number of lines without na: 119176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-6b7305125569>:8: UserWarning: Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  perimeter = np.asarray(df['geometry'].length)\n",
      "<ipython-input-6-6b7305125569>:13: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  area_values = np.asarray(df['geometry'].area)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible urban_type list : ['Dense Urban', 'Industrial', 'N,A', 'Rural', 'Sparse Urban', 'Urban Slum']\n",
      "possible geography_type list : ['Barren Land', 'Coastal', 'Dense Forest', 'Desert', 'Farms', 'Grass Land', 'Hills', 'Lakes', 'N,A', 'River', 'Snow', 'Sparse Forest']\n",
      "geography_type [[1 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 1 1 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n",
      "train_x.shape, train_y.shape, test_x.shape :\n",
      " (292758, 57) (292758,) (119176, 57)\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Feature engineering ---\")\n",
    "\n",
    "\n",
    "def get_features(df):\n",
    "    dic_features = {\"names\":[],\"features\":[]}\n",
    "\n",
    "    # geometry features\n",
    "    perimeter = np.asarray(df['geometry'].length)\n",
    "    perimeter = np.expand_dims(perimeter, axis=-1)\n",
    "    dic_features[\"features\"].append(perimeter)\n",
    "    dic_features[\"names\"].append(\"perimeter\")\n",
    "\n",
    "    area_values = np.asarray(df['geometry'].area)\n",
    "    area_values = np.expand_dims(area_values, axis=-1)\n",
    "    dic_features[\"features\"].append(area_values)\n",
    "    dic_features[\"names\"].append(\"area\")\n",
    "\n",
    "    ratio_area_over_perimeter = area_values/perimeter\n",
    "    dic_features[\"features\"].append(ratio_area_over_perimeter)\n",
    "    dic_features[\"names\"].append(\"ratio_area_over_perimeter\")\n",
    "\n",
    "    def get_ratio_length_min_max(exte):\n",
    "        x,y = exte.xy\n",
    "        lengths = [np.sqrt((x[i]-x[i+1])**2+(y[i]-y[i+1])**2) for i in range(4)]\n",
    "        return np.min(lengths)/np.max(lengths)\n",
    "    \n",
    "    ratio_length_min_max = np.asarray(df['geometry'].exterior.apply([get_ratio_length_min_max]))\n",
    "    dic_features[\"features\"].append(ratio_length_min_max)\n",
    "    dic_features[\"names\"].append(\"ratio_length_min_max\")\n",
    "\n",
    "    # diameter\n",
    "    '''\n",
    "    def get_coords(geom):\n",
    "        coords = list(geom.exterior.coords)\n",
    "        return (coords)\n",
    "\n",
    "    def get_diameter(coord):\n",
    "        arr_coord = np.array(coord)\n",
    "        distances = utils.get_distances(arr_coord,arr_coord)\n",
    "        return np.max(distances)\n",
    "\n",
    "    coords = train_df.geometry.apply(get_coords)\n",
    "    diameter = coords.apply(get_diameter)\n",
    "    diameter = np.asarray(diameter)\n",
    "    diameter = np.expand_dims(diameter,axis=-1)\n",
    "    dic_features[\"features\"].append(diameter)\n",
    "    dic_features[\"names\"].append(\"diameter\")\n",
    "\n",
    "    ratio_area_over_diameter = perimeter/diameter\n",
    "    dic_features[\"features\"].append(ratio_area_over_diameter)\n",
    "    dic_features[\"names\"].append(\"ratio_area_over_diameter\")\n",
    "\n",
    "    ratio_perimeter_over_diameter = area_values/diameter\n",
    "    dic_features[\"features\"].append(ratio_perimeter_over_diameter)\n",
    "    dic_features[\"names\"].append(\"ratio_perimeter_over_diameter\")\n",
    "'''\n",
    "    # geography features\n",
    "    mlb_urban_type = MultiLabelBinarizer()\n",
    "    urban_type = np.asarray(df[\"urban_type\"].apply(lambda x: x.split(\",\") if x!=\"N,A\" else [x]))\n",
    "    mlb_urban_type.fit(urban_type)\n",
    "    print(\"possible urban_type list :\", list(mlb_urban_type.classes_))\n",
    "    urban_type = mlb_urban_type.transform(urban_type)\n",
    "    dic_features[\"features\"].append(urban_type)\n",
    "    dic_features[\"names\"]+=list(mlb_urban_type.classes_)\n",
    "\n",
    "    mlb_geography_type = MultiLabelBinarizer()\n",
    "    geography_type = np.asarray(df[\"geography_type\"].apply(lambda x: x.split(\",\") if x!=\"N,A\" else [x]))\n",
    "    mlb_geography_type.fit(geography_type)\n",
    "    print(\"possible geography_type list :\", list(mlb_geography_type.classes_))\n",
    "    geography_type = mlb_geography_type.transform(geography_type)\n",
    "    print(\"geography_type\",geography_type)\n",
    "    dic_features[\"features\"].append(geography_type)\n",
    "    dic_features[\"names\"]+=list(mlb_geography_type.classes_)\n",
    "\n",
    "    # dates/images features\n",
    "    def get_sorted_date_diff_with_indices(df):\n",
    "        dates_to_add = []\n",
    "        for i in range(5):\n",
    "            date = df[f'date{i}'].apply(lambda x: int(str(x)[-4:]))\n",
    "            date = np.asarray(date)\n",
    "            date = np.expand_dims(date,axis=-1)\n",
    "            dates_to_add.append(date)\n",
    "\n",
    "        dates = np.concatenate(dates_to_add,axis=-1)\n",
    "\n",
    "        indices_dates = np.argsort(dates,axis=-1)\n",
    "        dates = np.array([dates[i,indices_dates[i,:]] for i in range(dates.shape[0])])\n",
    "\n",
    "        date_diff = dates - dates[:,-1:]@np.ones((1,5),dtype=int)\n",
    "        return date_diff, indices_dates\n",
    "\n",
    "    date_diff,indices_dates=get_sorted_date_diff_with_indices(df)\n",
    "    dic_features[\"features\"].append(date_diff)\n",
    "    dic_features[\"names\"]+=[f\"new_date_diff{i}\" for i in range(5)]\n",
    "\n",
    "    \n",
    "    trad_colors = {\"red\":0,\"blue\":1,\"green\":2}\n",
    "    def get_mean_std(df):\n",
    "        colors = list(trad_colors.keys())\n",
    "        res = np.zeros((df.shape[0],5,3,2))\n",
    "        for i in range(1,6):\n",
    "            for j_color,color in enumerate(colors):\n",
    "                res[:,i-1,j_color,0] = np.asarray(df[f\"img_{color}_mean_date{i}\"])\n",
    "                res[:,i-1,j_color,1] = np.asarray(df[f\"img_{color}_std_date{i}\"])\n",
    "                \n",
    "        return res\n",
    "\n",
    "    color_mean_std = get_mean_std(df)\n",
    "    color_mean_std = np.array([color_mean_std[i,indices_dates[i,:],:,:] for i in range(color_mean_std.shape[0])])\n",
    "\n",
    "    for i in range(color_mean_std.shape[2]):\n",
    "        for j in range(color_mean_std.shape[3]):\n",
    "            dic_features[\"features\"].append(color_mean_std[:,:,i,j])\n",
    "            dic_features[\"names\"]+=[f\"color_mean_std_{date}_{i}_{j}\" for date in range(5)]\n",
    "\n",
    "    res = np.concatenate(dic_features[\"features\"], axis=-1)\n",
    "\n",
    "    return res,dic_features\n",
    "\n",
    "\n",
    "train_df_without_na,train_indices,train_dummy_values = handle_na_in_df(train_df)\n",
    "train_x,train_dic_features= get_features(train_df_without_na)\n",
    "utils.display_features(train_dic_features)\n",
    "train_y = train_df_without_na['change_type'].apply(lambda x: change_type_map[x])\n",
    "\n",
    "test_df_without_na,test_indices,test_dummy_values = handle_na_in_df(test_df)\n",
    "test_x,_ = get_features(test_df_without_na)\n",
    "\n",
    "print(\"train_x.shape, train_y.shape, test_x.shape :\\n\",\n",
    "      train_x.shape, train_y.shape, test_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34773353 0.52094869 0.29277306 ... 0.5663036  0.89643648 0.53913295]\n"
     ]
    }
   ],
   "source": [
    "print(train_x[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- train ---\n",
      "f1_score on training set : 0.6364351117653569\n"
     ]
    }
   ],
   "source": [
    "\n",
    "######## Training ########\n",
    "\n",
    "print(\"--- train ---\")\n",
    "#rnd_clf = RandomForestClassifier(n_estimators=500,max_depth=50,max_leaf_nodes=30000, bootstrap =True, verbose=True, n_jobs=-1)\n",
    "\n",
    "#rnd_clf.fit(train_x,train_y)\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softprob\", random_state=42)\n",
    "xgb_fit = xgb_model.fit(train_x, train_y)\n",
    "\n",
    "pred_y=xgb_model.predict(train_x)\n",
    "\n",
    "#pred_y = rnd_clf.predict(train_x)\n",
    "print(\"f1_score on training set :\", f1_score(pred_y, train_y,average='macro'))\n",
    "\n",
    "# knn_clf = KNeighborsClassifier(n_neighbors=3,n_jobs=-1)\n",
    "# knn_clf.fit(train_x,train_y)\n",
    "# pred_y = knn_clf.predict(train_x)\n",
    "# print(\"f1_score on training set :\", f1_score(pred_y, train_y,average='macro'))\n",
    "\n",
    "do_cross_validation = False\n",
    "if do_cross_validation:\n",
    "    def display_scores(scores):\n",
    "        print(\"Scores:\",scores)\n",
    "        print(\"Mean\",scores.mean())\n",
    "        print(\"Std:\",scores.std())\n",
    "\n",
    "    scores = cross_val_score(xgb_fit,train_x,train_y,scoring=\"f1_macro\",cv=3)\n",
    "    display_scores(scores)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    max_leaf_nodes = trial.suggest_int(\"max_leaf_nodes\", 20000, 40000)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 100, 500)\n",
    "    rnd_clf = RandomForestClassifier(n_estimators=n_estimators,max_leaf_nodes=max_leaf_nodes, bootstrap=True, verbose=True, n_jobs=-1)\n",
    "\n",
    "    scores = cross_val_score(rnd_clf,train_x,train_y,scoring=\"f1_macro\",cv=4)\n",
    "    return scores.mean()\n",
    "\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=10)\n",
    "best_params = study.best_params\n",
    "found_n_estimators = best_params[\"n_estimators\"]\n",
    "found_max_leaf_nodes = best_params[\"max_leaf_nodes\"]\n",
    "\n",
    "\n",
    "import yaml\n",
    "\n",
    "with open('hp_optim.yaml', 'w') as outfile:\n",
    "    yaml.dump({\"found_max_leaf_nodes\":found_max_leaf_nodes,\"found_n_estimators\":found_n_estimators}, outfile, default_flow_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(found_n_estimators,found_max_leaf_nodes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the most promising features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "perimeter importance: 0.10252459\n",
      "area importance: 0.009688108\n",
      "ratio_area_over_perimeter importance: 0.032066382\n",
      "ratio_length_min_max importance: 0.027215099\n",
      "Dense Urban importance: 0.040600527\n",
      "Industrial importance: 0.08860667\n",
      "N,A importance: 0.013212343\n",
      "Rural importance: 0.011904547\n",
      "Sparse Urban importance: 0.007516959\n",
      "Urban Slum importance: 0.026921947\n",
      "Barren Land importance: 0.01590423\n",
      "Coastal importance: 0.008767088\n",
      "Dense Forest importance: 0.021068523\n",
      "Desert importance: 0.056689415\n",
      "Farms importance: 0.01770743\n",
      "Grass Land importance: 0.011639733\n",
      "Hills importance: 0.0058985944\n",
      "Lakes importance: 0.021160329\n",
      "N,A importance: 0.008639079\n",
      "River importance: 0.015072792\n",
      "Snow importance: 0.0028139518\n",
      "Sparse Forest importance: 0.014336831\n",
      "new_date_diff0 importance: 0.026974026\n",
      "new_date_diff1 importance: 0.029096404\n",
      "new_date_diff2 importance: 0.0318106\n",
      "new_date_diff3 importance: 0.024350034\n",
      "new_date_diff4 importance: 0.0\n",
      "color_mean_std_0_0_0 importance: 0.011815502\n",
      "color_mean_std_1_0_0 importance: 0.010316533\n",
      "color_mean_std_2_0_0 importance: 0.010038922\n",
      "color_mean_std_3_0_0 importance: 0.011489634\n",
      "color_mean_std_4_0_0 importance: 0.012578814\n",
      "color_mean_std_0_0_1 importance: 0.008627351\n",
      "color_mean_std_1_0_1 importance: 0.0070397183\n",
      "color_mean_std_2_0_1 importance: 0.0152916275\n",
      "color_mean_std_3_0_1 importance: 0.0069736787\n",
      "color_mean_std_4_0_1 importance: 0.009391034\n",
      "color_mean_std_0_1_0 importance: 0.014064531\n",
      "color_mean_std_1_1_0 importance: 0.012120543\n",
      "color_mean_std_2_1_0 importance: 0.0142006595\n",
      "color_mean_std_3_1_0 importance: 0.013192046\n",
      "color_mean_std_4_1_0 importance: 0.015031458\n",
      "color_mean_std_0_1_1 importance: 0.011218736\n",
      "color_mean_std_1_1_1 importance: 0.022231335\n",
      "color_mean_std_2_1_1 importance: 0.010604894\n",
      "color_mean_std_3_1_1 importance: 0.009583279\n",
      "color_mean_std_4_1_1 importance: 0.009935175\n",
      "color_mean_std_0_2_0 importance: 0.008076015\n",
      "color_mean_std_1_2_0 importance: 0.006562913\n",
      "color_mean_std_2_2_0 importance: 0.006804045\n",
      "color_mean_std_3_2_0 importance: 0.0088497745\n",
      "color_mean_std_4_2_0 importance: 0.008069838\n",
      "color_mean_std_0_2_1 importance: 0.014369229\n",
      "color_mean_std_1_2_1 importance: 0.009241433\n",
      "color_mean_std_2_2_1 importance: 0.011315389\n",
      "color_mean_std_3_2_1 importance: 0.008423361\n",
      "color_mean_std_4_2_1 importance: 0.010356375\n"
     ]
    }
   ],
   "source": [
    "def display_feature_importances(dic_features,clf):\n",
    "    for i,feat_name in enumerate(dic_features[\"names\"]):\n",
    "        print(f\"{feat_name} importance:\",xgb_fit.feature_importances_[i]) \n",
    "\n",
    "display_feature_importances(train_dic_features,xgb_fit)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction on test set shape : (119176,)\n",
      "[3 2 2 ... 3 2 2]\n",
      "pred_y.shape after: (120526,)\n",
      "(1350,)\n",
      "(120526,)\n",
      "(120526, 1) (120526, 1)\n",
      "[0 0 0 ... 5 5 5]\n",
      "--- save ---\n"
     ]
    }
   ],
   "source": [
    "pred_y = xgb_model.predict(test_x)\n",
    "print(\"prediction on test set shape :\", pred_y.shape)\n",
    "print(pred_y)\n",
    "\n",
    "pred_y = np.concatenate([pred_y,test_dummy_values],axis=0)\n",
    "print(\"pred_y.shape after:\",pred_y.shape)\n",
    "print(test_dummy_values.shape)\n",
    "print(test_indices.shape)\n",
    "new_test_indices = np.expand_dims(test_indices,axis=-1)\n",
    "new_pred = np.expand_dims(pred_y,axis=-1)\n",
    "print(new_pred.shape,new_test_indices.shape)\n",
    "new_pred_y = np.concatenate([new_test_indices,new_pred],axis=-1)\n",
    "new_pred_y = new_pred_y[np.argsort(new_pred[:,0],axis=0),1]\n",
    "new_pred_y = new_pred_y.astype(int)\n",
    "print(new_pred_y)\n",
    "\n",
    "\n",
    "######## Save results to submission file ########\n",
    "print(\"--- save ---\")\n",
    "pred_df = pd.DataFrame(new_pred_y, columns=['change_type'])\n",
    "pred_df.to_csv(\"my_submission.csv\", index=True, index_label='Id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_geoproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (tags/v3.10.6:9c7b4bd, Aug  1 2022, 21:53:49) [MSC v.1932 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5a691981180cc6a4785b1489b0832c35bb891551f8845804eee4cb510316e0ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
