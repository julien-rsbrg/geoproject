{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 81,
=======
   "execution_count": 1,
>>>>>>> bc30d58cab953b1840534e89049864d2a7a57183
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- read .csv files ---\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script can be used as skeleton code to read the challenge train and test\n",
    "geojsons, to train a trivial model, and write data to the submission file.\n",
    "\"\"\"\n",
    "# data handling\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# data analysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "change_type_map = {'Demolition': 0, 'Road': 1, 'Residential': 2, 'Commercial': 3, 'Industrial': 4,\n",
    "                   'Mega Projects': 5}\n",
    "\n",
    "# Read csvs\n",
    "print(\"--- read .csv files ---\")\n",
    "train_df = gpd.read_file('train.geojson', index_col=0)\n",
    "\n",
    "test_df = gpd.read_file('test.geojson', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_without_nan = train_df.dropna()\n",
    "test_df_without_nan = test_df.dropna()\n"
=======
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_ratio(exte):\n",
    "    x, y = exte.xy\n",
    "    lengths = [\n",
    "        np.sqrt((x[i] - x[i + 1]) ** 2 + (y[i] - y[i + 1]) ** 2) for i in range(4)\n",
    "    ]\n",
    "    return min(lengths) / max(lengths)\n"
>>>>>>> bc30d58cab953b1840534e89049864d2a7a57183
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_date_diff_with_indices(df):\n",
    "    dates_to_add = []\n",
    "    for i in range(5):\n",
    "        date = df[f'date{i}'].apply(lambda x: int(str(x)[-4:]))\n",
    "        date = np.asarray(date)\n",
    "        date = np.expand_dims(date,axis=-1)\n",
    "        dates_to_add.append(date)\n",
    "\n",
    "    dates = np.concatenate(dates_to_add,axis=-1)\n",
    "\n",
    "    indices_dates = np.argsort(dates,axis=-1)\n",
    "    dates = np.array([dates[i,indices_dates[i,:]] for i in range(dates.shape[0])])\n",
    "\n",
    "    date_diff = dates - dates[:,-1:]@np.ones((1,4),dtype=int)\n",
    "    return date_diff, indices_dates\n",
    "\n",
    "date_diff,indices_dates=get_sorted_date_diff_with_indices(train_df.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([125.77306236, 133.09767932, 120.71349035, ..., 111.30431979,\n",
       "       137.374613  , 176.84126984])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trad_colors = {\"red\":0,\"blue\":1,\"green\":2}\n",
    "\n",
    "def get_mean_std(df):\n",
    "    colors = list(trad_colors.keys())\n",
    "    res = np.zeros((df.shape[0],5,3,2))\n",
    "    for i in range(1,6):\n",
    "        for j_color,color in enumerate(colors):\n",
    "            res[:,i-1,j_color,0] = np.asarray(df[f\"img_{color}_mean_date{i}\"])\n",
    "            res[:,i-1,j_color,1] = np.asarray(df[f\"img_{color}_std_date{i}\"])\n",
    "            \n",
    "    return res\n",
    "\n",
    "color_mean_std = get_mean_std(train_df.dropna())\n",
    "color_mean_std = np.array([color_mean_std[i,indices_dates[i,:],:,:] for i in range(color_mean_std.shape[0])])\n",
    "color_mean_std[:,0,trad_colors[\"red\"],0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
=======
   "execution_count": 11,
>>>>>>> bc30d58cab953b1840534e89049864d2a7a57183
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Feature engineering ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tabba\\AppData\\Local\\Temp\\ipykernel_12308\\3596240067.py:9: UserWarning: Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  perimeter = np.asarray(df['geometry'].length)\n",
      "C:\\Users\\tabba\\AppData\\Local\\Temp\\ipykernel_12308\\3596240067.py:13: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  area_values = np.asarray(df['geometry'].area)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible urban_type list : ['Dense Urban', 'Dense Urban,Industrial', 'Dense Urban,Rural', 'Dense Urban,Urban Slum', 'Industrial', 'N,A', 'Rural', 'Rural,Industrial', 'Sparse Urban', 'Sparse Urban,Dense Urban', 'Sparse Urban,Industrial', 'Sparse Urban,Rural', 'Sparse Urban,Urban Slum', 'Sparse Urban,Urban Slum,Industrial', 'Urban Slum', 'Urban Slum,Industrial', 'Urban Slum,Rural']\n",
      "possible geography_type list : ['Dense Urban', 'Dense Urban,Industrial', 'Dense Urban,Rural', 'Dense Urban,Urban Slum', 'Industrial', 'N,A', 'Rural', 'Rural,Industrial', 'Sparse Urban', 'Sparse Urban,Dense Urban', 'Sparse Urban,Industrial', 'Sparse Urban,Rural', 'Sparse Urban,Urban Slum', 'Sparse Urban,Urban Slum,Industrial', 'Urban Slum', 'Urban Slum,Industrial', 'Urban Slum,Rural']\n",
      "(296146, 1)\n",
      "(296146, 1)\n",
      "(296146, 1)\n",
      "(296146, 1)\n",
      "(296146, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tabba\\AppData\\Local\\Temp\\ipykernel_12308\\3596240067.py:9: UserWarning: Geometry is in a geographic CRS. Results from 'length' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  perimeter = np.asarray(df['geometry'].length)\n",
      "C:\\Users\\tabba\\AppData\\Local\\Temp\\ipykernel_12308\\3596240067.py:13: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  area_values = np.asarray(df['geometry'].area)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "possible urban_type list : ['Dense Urban', 'Dense Urban,Industrial', 'Dense Urban,Rural', 'Dense Urban,Urban Slum', 'Industrial', 'N,A', 'Rural', 'Rural,Industrial', 'Sparse Urban', 'Sparse Urban,Dense Urban', 'Sparse Urban,Industrial', 'Sparse Urban,Rural', 'Sparse Urban,Urban Slum', 'Sparse Urban,Urban Slum,Industrial', 'Urban Slum', 'Urban Slum,Industrial', 'Urban Slum,Rural']\n",
      "possible geography_type list : ['Dense Urban', 'Dense Urban,Industrial', 'Dense Urban,Rural', 'Dense Urban,Urban Slum', 'Industrial', 'N,A', 'Rural', 'Rural,Industrial', 'Sparse Urban', 'Sparse Urban,Dense Urban', 'Sparse Urban,Industrial', 'Sparse Urban,Rural', 'Sparse Urban,Urban Slum', 'Sparse Urban,Urban Slum,Industrial', 'Urban Slum', 'Urban Slum,Industrial', 'Urban Slum,Rural']\n",
      "(120526, 1)\n",
      "(120526, 1)\n",
      "(120526, 1)\n",
      "(120526, 1)\n",
      "(120526, 1)\n",
      "train_x.shape, train_y.shape, test_x.shape :\n",
      " (296146, 5) (296146,) (120526, 5)\n"
     ]
    }
   ],
   "source": [
    "######## Feature engineering ########\n",
    "print(\"--- Feature engineering ---\")\n",
    "\n",
    "\n",
    "def get_features(df):\n",
    "    features = []\n",
    "\n",
    "    # geometry features\n",
    "    perimeter = np.asarray(df['geometry'].length)\n",
    "    perimeter = np.expand_dims(perimeter, axis=-1)\n",
    "    features.append(perimeter)\n",
    "\n",
    "    area_values = np.asarray(df['geometry'].area)\n",
    "    area_values = np.expand_dims(area_values, axis=-1)\n",
    "    features.append(area_values)\n",
    "\n",
    "    ratios = np.asarray(df[\"geometry\"].exterior.apply(length_ratio))\n",
    "    ratios = np.expand_dims(ratios, axis=-1)\n",
    "    features.append(ratios)\n",
    "    \n",
    "    # geography features\n",
    "    le_urban_type = LabelEncoder()\n",
    "    le_urban_type.fit(np.asarray(df[\"urban_type\"]))\n",
    "    print(\"possible urban_type list :\", list(le_urban_type.classes_))\n",
    "    urban_type = np.asarray(df[\"urban_type\"])\n",
    "    urban_type = le_urban_type.transform(urban_type)\n",
    "    urban_type = np.expand_dims(urban_type, axis=-1)\n",
    "    features.append(urban_type)\n",
    "\n",
    "    le_geography_type = LabelEncoder()\n",
    "    le_geography_type.fit(np.asarray(df[\"geography_type\"]))\n",
    "    print(\"possible geography_type list :\", list(le_geography_type.classes_))\n",
    "    geography_type = np.asarray(df[\"geography_type\"])\n",
    "    geography_type = le_urban_type.transform(geography_type)\n",
    "    geography_type = np.expand_dims(geography_type, axis=-1)\n",
    "    features.append(geography_type)\n",
    "\n",
    "    # dates/images features\n",
    "    def get_sorted_date_diff_with_indices(df):\n",
    "        dates_to_add = []\n",
    "        for i in range(5):\n",
    "            date = df[f'date{i}'].apply(lambda x: int(str(x)[-4:]))\n",
    "            date = np.asarray(date)\n",
    "            date = np.expand_dims(date,axis=-1)\n",
    "            dates_to_add.append(date)\n",
    "\n",
    "        dates = np.concatenate(dates_to_add,axis=-1)\n",
    "\n",
    "        indices_dates = np.argsort(dates,axis=-1)\n",
    "        dates = np.array([dates[i,indices_dates[i,:]] for i in range(dates.shape[0])])\n",
    "\n",
    "        date_diff = dates - dates[:,-1:]@np.ones((1,4),dtype=int)\n",
    "        return date_diff, indices_dates\n",
    "\n",
    "    date_diff,indices_dates=get_sorted_date_diff_with_indices(df)\n",
    "    features.append(date_diff)\n",
    "\n",
    "    \n",
    "    trad_colors = {\"red\":0,\"blue\":1,\"green\":2}\n",
    "    def get_mean_std(df):\n",
    "        colors = list(trad_colors.keys())\n",
    "        res = np.zeros((df.shape[0],5,3,2))\n",
    "        for i in range(1,6):\n",
    "            for j_color,color in enumerate(colors):\n",
    "                res[:,i-1,j_color,0] = np.asarray(df[f\"img_{color}_mean_date{i}\"])\n",
    "                res[:,i-1,j_color,1] = np.asarray(df[f\"img_{color}_std_date{i}\"])\n",
    "                \n",
    "        return res\n",
    "\n",
    "    color_mean_std = get_mean_std(train_df.dropna())\n",
    "    color_mean_std = np.array([color_mean_std[i,indices_dates[i,:],:,:] for i in range(color_mean_std.shape[0])])\n",
    "\n",
    "    for i in range(color_mean_std.shape[2]):\n",
    "        for j in range(color_mean_std.shape[3]):\n",
    "            features.append(color_mean_std[:,:,i,j])\n",
    "\n",
    "    for feat in features:\n",
    "        print(feat.shape)\n",
    "\n",
    "    res = np.concatenate(features, axis=-1)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "train_x = get_features(train_df)\n",
    "train_y = train_df['change_type'].apply(lambda x: change_type_map[x])\n",
    "\n",
    "test_x = get_features(test_df)\n",
    "\n",
    "print(\"train_x.shape, train_y.shape, test_x.shape :\\n\",\n",
    "      train_x.shape, train_y.shape, test_x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- train ---\n",
      "!!! mean f1 score on -training- set !!!\n",
      "KNeighborsClassifier 0.4323063559091879\n",
      "RandomForestClassifier 0.8879283186283639\n",
      "BaggingClassifier 0.23938966280830376\n",
      "f1_score on training set : 0.5408221063434642\n",
      "prediction on test set shape : (120526,)\n",
      "--- save ---\n"
     ]
    }
   ],
   "source": [
    "######## Training ########\n",
    "\n",
    "print(\"--- train ---\")\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3)\n",
    "rnd_clf = RandomForestClassifier()\n",
    "# WARNING : svm_clf not functional !\n",
    "bag_clf = BaggingClassifier(DecisionTreeClassifier(),n_estimators=500,max_samples=100,bootstrap=True,n_jobs=1)\n",
    "estimators = [('knn', knn_clf), ('rf', rnd_clf), ('bag',bag_clf)]\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=estimators, voting='soft')\n",
    "\n",
    "print('!!! mean f1 score on -training- set !!!')\n",
    "for name,clf in estimators:\n",
    "    clf.fit(train_x, train_y)\n",
    "    pred_y = clf.predict(train_x)\n",
    "    print(clf.__class__.__name__, f1_score(pred_y, train_y,average='macro'))\n",
    "\n",
    "voting_clf.fit(train_x,train_y)\n",
    "pred_y = voting_clf.predict(train_x)\n",
    "print(\"f1_score on training set :\", f1_score(pred_y, train_y,average='macro'))\n",
    "\n",
    "pred_y = voting_clf.predict(test_x)\n",
    "print(\"prediction on test set shape :\", pred_y.shape)\n",
    "\n",
    "######## Save results to submission file ########\n",
    "print(\"--- save ---\")\n",
    "pred_df = pd.DataFrame(pred_y, columns=['change_type'])\n",
    "pred_df.to_csv(\"my_submission2.csv\", index=True, index_label='Id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score on training set, random forest : 0.8853366745790859\n",
      "prediction on test set shape : (120526,)\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(train_x, train_y)\n",
    "pred_y = rf.predict(train_x)\n",
    "print(\"f1_score on training set, random forest :\", f1_score(pred_y, train_y,average='macro'))\n",
    "\n",
    "pred_y = rf.predict(test_x)\n",
    "print(\"prediction on test set shape :\", pred_y.shape)\n",
    "\n",
    "random_forest = pd.DataFrame(pred_y, columns=['change_type'])\n",
    "random_forest.to_csv(\"perso_true_rf1.csv\", index=True, index_label='Id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_geoproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.10.6"
=======
   "version": "3.9.7"
>>>>>>> bc30d58cab953b1840534e89049864d2a7a57183
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "42d98e48f84d14f5f5a88ebf3fab2ab7d69fea5b2b2d4e1c11495b404d9fea7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
